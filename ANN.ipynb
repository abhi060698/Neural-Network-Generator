{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required header files\n",
    "import keras\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import msvcrt as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the modules needed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    \n",
    "    def __init__(self,X,Y,nodes,model=model,activation='softmax',loss='categorical_crossentropy',optimizer='adam',epochs=10,batch_size=200,kernel_init='normal'):#constructor\n",
    "        self.X              = [[X[i][j] for j in range(len(X[i]))] for i in range(len(X))]       \n",
    "        self.Y              = [Y[i] for i in range(len(Y))]                                      \n",
    "        self.input_dim      = nodes[0]                                                           \n",
    "        self.nodes          = [nodes[i] for i in range(len(nodes))]                              \n",
    "        self.model          = model                                                              \n",
    "        self.layers         = len(nodes)                                                                                      \n",
    "        self.activation     = activation                                                                                     \n",
    "        self.loss           = loss                                                               \n",
    "        self.optimizer      = optimizer                                                     \n",
    "        self.epochs         = epochs                                                             \n",
    "        self.batch_size     = batch_size                                                         \n",
    "        self.kernel_init    = kernel_init                                                       \n",
    "                                                                    \n",
    "        \n",
    "        self.model.add(Dense(self.nodes[0],input_dim=self.input_dim, kernel_initializer=self.kernel_init,activation='relu'))  \n",
    "        \n",
    "       \n",
    "        if(self.layers>2):\n",
    "            for i in range(1,self.layers-1):\n",
    "                self.model.add(Dense(self.nodes[i], kernel_initializer=self.kernel_init,activation='relu'))            \n",
    "        \n",
    "        self.model.add(Dense(self.nodes[(self.layers)-1], kernel_initializer=self.kernel_init,activation=self.activation))  \n",
    "        \n",
    "        self.model.compile(loss=self.loss,optimizer=self.optimizer,metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        \n",
    "        np.random.seed(7)\n",
    "        self.model.fit(np.array(self.X),np.array(self.Y),epochs= self.epochs,batch_size=self.batch_size,verbose=2)\n",
    "        \n",
    "        \n",
    "        scores               = self.model.evaluate(np.array(self.X), np.array(self.Y),verbose=0)\n",
    "        print(\"\\n%s: %.2f%%\" % (\"accuracy of the classifier on the training dataset \", scores[1]*100))\n",
    "            \n",
    "     \n",
    "    def check_accuracy(self,P,Q):#check the accuracy of the trained model on test data\n",
    "        scores               = self.model.evaluate(np.array(P), np.array(Q),verbose=0)\n",
    "        print(\"\\n%s: %.2f%%\" % (\"accuracy of the classifier on the validation dataset \", scores[1]*100))\n",
    "        \n",
    "    def test_code(self,P,Q):#check the accuracy of the trained model on test data\n",
    "        np.random.seed(7)\n",
    "        scores               = self.model.evaluate(np.array(P), np.array(Q),verbose=0)\n",
    "        if(scores[1]>0.97):\n",
    "            print(\"\\n%s: %.2f%%\" % (\"accuracy of the classifier on the validation dataset \", scores[1]*100))\n",
    "            print(\"code passes the test\")\n",
    "            \n",
    "        else:\n",
    "            print(\"code has failed the test\")\n",
    "            \n",
    "        \n",
    "        \n",
    "    def predict(self,X_new):#make predictions for new feature data\n",
    "        predictions = self.model.predict(X_new)\n",
    "        df = X_new[:,0]\n",
    "        df['predictions']=predictions\n",
    "        df.to_csv('predictions.csv')\n",
    "        \n",
    "    def save_model_and_weights(self):#save the model as a json file to disk\n",
    "        #saving model and weights\n",
    "        model_json = self.model.to_json()\n",
    "        with open(\"model.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        self.model.save_weights(\"model.h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "        \n",
    "   \n",
    "\n",
    "class Retrain:\n",
    "    \n",
    "    def __init__(self,json_file,output_dim,X,Y,epochs=10,batch_size=200):\n",
    "        self.model          = model\n",
    "        self.json_file      = json_file\n",
    "        self.output_dim     = output_dim\n",
    "        self.X              = [[X[i][j] for j in range(len(X[i]))] for i in range(len(X))]\n",
    "        self.Y              = [Y[i] for i in range(len(Y))] \n",
    "        self.epochs         = epochs\n",
    "        self.batch_size     = batch_size\n",
    "        \n",
    "        #loading the new model\n",
    "        json_file = open(self.json_file, 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model2= model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        model2.load_weights(\"model.h5\")\n",
    "        print(\"Loaded model from disk\")\n",
    "        \n",
    "        self.model2.layers.pop()\n",
    "        self.model2.add(Dense(self.output_dim,activation=activation))\n",
    "        \n",
    "        self.model.fit(np.array(self.X),np.array(self.Y),epochs= self.epochs,batch_size=self.batch_size,verbose=2)\n",
    "        \n",
    "        scores               = self.model.evaluate(np.array(self.X), np.array(self.Y))\n",
    "        print(\"\\n%s: %.2f%%\" % (\"accuracy of the incrementally trained classifier on the training dataset \", scores[1]*100))\n",
    "            \n",
    "        \n",
    "    def check_accuracy(self,choice,P,Q):#check accuracy of the incrementally trained model \n",
    "        scores               = self.model2.evaluate(np.array(P), np.array(Q))\n",
    "        print(\"\\n%s: %.2f%%\" % (\"accuracy of the incrementally trained classifier on the validation dataset \", scores[1]*100))\n",
    "        \n",
    "       \n",
    "    def predict(self,X_new):#make predictions using incrementally trained model\n",
    "        predictions = self.model2.predict(X_new)\n",
    "        df = X_new[:,0]\n",
    "        df['predictions']=predictions\n",
    "        df.to_csv('predictions2.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(): #perform a test to see if the code works using the MNIST dataset\n",
    "    from keras.datasets import mnist\n",
    "    np.random.seed(7)\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "    X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "    X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    y_train = np_utils.to_categorical(y_train,10)\n",
    "    y_test = np_utils.to_categorical(y_test,10)\n",
    "    num_classes = y_test.shape[0]\n",
    "    c=ANN(X_train,y_train,[784,10])\n",
    "    proceed=c.test_code(X_test,y_test)\n",
    "    return proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 623,290\n",
      "Trainable params: 623,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.2803 - acc: 0.9193\n",
      "Epoch 2/10\n",
      " - 9s - loss: 0.1125 - acc: 0.9679\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.0713 - acc: 0.9795\n",
      "Epoch 4/10\n",
      " - 8s - loss: 0.0506 - acc: 0.9854\n",
      "Epoch 5/10\n",
      " - 8s - loss: 0.0375 - acc: 0.9888\n",
      "Epoch 6/10\n",
      " - 8s - loss: 0.0266 - acc: 0.9931\n",
      "Epoch 7/10\n",
      " - 8s - loss: 0.0204 - acc: 0.9946\n",
      "Epoch 8/10\n",
      " - 8s - loss: 0.0156 - acc: 0.9961\n",
      "Epoch 9/10\n",
      " - 7s - loss: 0.0105 - acc: 0.9980\n",
      "Epoch 10/10\n",
      " - 8s - loss: 0.0080 - acc: 0.9985\n",
      "\n",
      "accuracy of the classifier on the training dataset : 99.89%\n",
      "\n",
      "accuracy of the classifier on the validation dataset : 98.21%\n",
      "code passes the test\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self,X,Y,nodes=,model=model,activation='softmax',loss='categorical_crossentropy',optimizer='adam',\n",
      "         epochs=10,batch_size=200,kernel_init='normal') are the parameters of the constructors for class ANN\n",
      "         \n",
      "         X,Y and input_dim are the essential parameters.The remaining parameters are all optional.\n",
      "         \n",
      "         An example of a call to the constructor is :      c = ANN(X,Y,20)\n",
      "         \n",
      "         However, if we want to replace certain defaults,  c = ANN(X,Y,20,optimixer='RMSProp')\n"
     ]
    }
   ],
   "source": [
    "print('''(self,X,Y,nodes=,model=model,activation='softmax',loss='categorical_crossentropy',optimizer='adam',\n",
    "         epochs=10,batch_size=200,kernel_init='normal') are the parameters of the constructors for class ANN\n",
    "         \n",
    "         X,Y and input_dim are the essential parameters.The remaining parameters are all optional.\n",
    "         \n",
    "         An example of a call to the constructor is :      c = ANN(X,Y,20)\n",
    "         \n",
    "         However, if we want to replace certain defaults,  c = ANN(X,Y,20,optimixer='RMSProp')''' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
